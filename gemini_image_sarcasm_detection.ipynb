{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import Image, display\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "generation_config = genai.GenerationConfig(\n",
    "    temperature=0.8,\n",
    "    top_p=1.0,\n",
    "    top_k=32,\n",
    "    candidate_count=1,\n",
    "    max_output_tokens=8192,\n",
    ")\n",
    "\n",
    "# Set safety settings\n",
    "safety_settings = [\n",
    "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv_files/200-annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"submissionId\", \"submissionTitle\", \"isTextSarcastic?\", \"isImageSarcastic?\", \"isTogetherSarcastic?\"]\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submissionId</th>\n",
       "      <th>submissionTitle</th>\n",
       "      <th>isTextSarcastic?</th>\n",
       "      <th>isImageSarcastic?</th>\n",
       "      <th>isTogetherSarcastic?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8q9bjm</td>\n",
       "      <td>finally someone said it\\n he's right. you are ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glf93t</td>\n",
       "      <td>pure evil\\n this attempt on my life has left m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kctb6e</td>\n",
       "      <td>sounded way better in my head\\n i remember whe...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j9qaro</td>\n",
       "      <td>totally relatable\\n why do we do this?! i dont...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i5z2pf</td>\n",
       "      <td>we weren’t expecting special forces\\n this guy...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submissionId                                    submissionTitle  \\\n",
       "0       8q9bjm  finally someone said it\\n he's right. you are ...   \n",
       "1       glf93t  pure evil\\n this attempt on my life has left m...   \n",
       "2       kctb6e  sounded way better in my head\\n i remember whe...   \n",
       "3       j9qaro  totally relatable\\n why do we do this?! i dont...   \n",
       "4       i5z2pf  we weren’t expecting special forces\\n this guy...   \n",
       "\n",
       "   isTextSarcastic?  isImageSarcastic?  isTogetherSarcastic?  \n",
       "0                 0                  1                     1  \n",
       "1                 0                  1                     1  \n",
       "2                 0                  1                     1  \n",
       "3                 0                  1                     1  \n",
       "4                 0                  1                     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing new columns for llm generated annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submissionId</th>\n",
       "      <th>submissionTitle</th>\n",
       "      <th>isTextSarcastic?</th>\n",
       "      <th>isImageSarcastic?</th>\n",
       "      <th>isTogetherSarcastic?</th>\n",
       "      <th>i_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8q9bjm</td>\n",
       "      <td>finally someone said it\\n he's right. you are ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glf93t</td>\n",
       "      <td>pure evil\\n this attempt on my life has left m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kctb6e</td>\n",
       "      <td>sounded way better in my head\\n i remember whe...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j9qaro</td>\n",
       "      <td>totally relatable\\n why do we do this?! i dont...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i5z2pf</td>\n",
       "      <td>we weren’t expecting special forces\\n this guy...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submissionId                                    submissionTitle  \\\n",
       "0       8q9bjm  finally someone said it\\n he's right. you are ...   \n",
       "1       glf93t  pure evil\\n this attempt on my life has left m...   \n",
       "2       kctb6e  sounded way better in my head\\n i remember whe...   \n",
       "3       j9qaro  totally relatable\\n why do we do this?! i dont...   \n",
       "4       i5z2pf  we weren’t expecting special forces\\n this guy...   \n",
       "\n",
       "   isTextSarcastic?  isImageSarcastic?  isTogetherSarcastic?   i_s  \n",
       "0                 0                  1                     1  None  \n",
       "1                 0                  1                     1  None  \n",
       "2                 0                  1                     1  None  \n",
       "3                 0                  1                     1  None  \n",
       "4                 0                  1                     1  None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['i_s'] = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_prompt_for_image_labels():\n",
    "    image_prompt = f\"\"\"\n",
    "    TASK:\n",
    "    You will be given an image, and your task is to determine whether the image contains sarcasm. \n",
    "    Indicate your response with a 1 if sarcasm is detected and a 0 if it is not sarcastic.\n",
    "\n",
    "    EXAMPLES:\n",
    "    \"\"\"\n",
    "    examples = [\n",
    "        (\"Sample Images/ayezy8.png\", '{\"isImageSarcastic?\": 1}'),\n",
    "        (\"Sample Images/epymwl.png\", '{\"isImageSarcastic?\": 1}'),\n",
    "        (\"Sample Images/tumor.png\", '{\"isImageSarcastic?\": 1}'),\n",
    "        (\"Sample Images/oil_painting.png\", '{\"isImageSarcastic?\": 1}'),\n",
    "        (\"Sample Images/cable.png\", '{\"isImageSarcastic?\": 0}'),\n",
    "        (\"Sample Images/snake.png\", '{\"isImageSarcastic?\": 0}'),\n",
    "        (\"Sample Images/Traffic_bounded.png\", '{\"isImageSarcastic?\": 0}'),\n",
    "        (\"Sample Images/university.png\", '{\"isImageSarcastic?\": 0}'),\n",
    "    ]\n",
    "\n",
    "    message = [image_prompt]\n",
    "    for image, resp in examples:\n",
    "        message = message + [\n",
    "            PIL.Image.open(image),\n",
    "            resp\n",
    "        ]\n",
    "\n",
    "    return message\n",
    "\n",
    "# Defining a response schema in order to obtain consistently formatted response\n",
    "response_schema_image = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"isImageSarcastic?\": {\n",
    "                \"type\": \"integer\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"isImageSarcastic?\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "def detect_sarcasm_in_image(image:str) -> str:\n",
    "    response = model.generate_content(\n",
    "        provide_prompt_for_image_labels() + [\n",
    "            PIL.Image.open(image)\n",
    "        ],\n",
    "        safety_settings=safety_settings,\n",
    "        generation_config = genai.GenerationConfig(\n",
    "            response_mime_type=\"application/json\", response_schema=response_schema_image\n",
    "        )\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIRECTORY = \"/Users/sinngamkhaidem/Developer/Datasets/Multimodal-Sarcasm-Dataset/annotated/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "curIndex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'isImageSarcastic?': 0}]\n",
      "[{'isImageSarcastic?': 0}]\n",
      "[{'isImageSarcastic?': 1}]\n",
      "[{'isImageSarcastic?': 0}]\n",
      "[{'isImageSarcastic?': 0}]\n",
      "[{'isImageSarcastic?': 0}]\n",
      "[{'isImageSarcastic?': 0}]\n",
      "[{'isImageSarcastic?': 0}]\n",
      "[{'isImageSarcastic?': 1}]\n",
      "[{'isImageSarcastic?': 1}]\n",
      "[{'isImageSarcastic?': 0}]\n",
      "[{'isImageSarcastic?': 1}]\n",
      "[{'isImageSarcastic?': 0}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(curIndex, df.shape[0]):\n",
    "    if i%2 == 0:\n",
    "        img = os.path.join(IMAGE_DIRECTORY, f\"{df.iloc[i]['submissionId']}.png\")\n",
    "        response = detect_sarcasm_in_image(img)\n",
    "        curIndex = i\n",
    "        if len(response)>0:\n",
    "            response_as_dict = json.loads(response)\n",
    "            print(response_as_dict)\n",
    "            df.at[i, 'i_s'] = response_as_dict[0]['isImageSarcastic?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[df['i_s'].notnull()]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes accuracy by comparing the true labels with the predicted labels.\n",
    "    \"\"\"\n",
    "    correct_predictions = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred))\n",
    "    accuracy = correct_predictions / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def compute_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes precision by calculating the ratio of true positives to the sum of true and false positives.\n",
    "    \"\"\"\n",
    "    true_positives = sum((y_t == 1 and y_p == 1) for y_t, y_p in zip(y_true, y_pred))\n",
    "    predicted_positives = sum(y_p == 1 for y_p in y_pred)\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    return precision\n",
    "\n",
    "def compute_recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes recall by calculating the ratio of true positives to the sum of true positives and false negatives.\n",
    "    \"\"\"\n",
    "    true_positives = sum((y_t == 1 and y_p == 1) for y_t, y_p in zip(y_true, y_pred))\n",
    "    actual_positives = sum(y_t == 1 for y_t in y_true)\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    return recall\n",
    "\n",
    "def compute_f1(precision, recall):\n",
    "    \"\"\"\n",
    "    Computes F1 score as the harmonic mean of precision and recall.\n",
    "    \"\"\"\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    accuracy = compute_accuracy(y_true, y_pred)\n",
    "    precision = compute_precision(y_true, y_pred)\n",
    "    recall = compute_recall(y_true, y_pred)\n",
    "    f1 = compute_f1(precision, recall)\n",
    "    print(\"\\tAccuracy: \", accuracy, \"\\n\", \"\\tPrecision: \", precision,\"\\n\", \"\\tRecall: \", recall, \"\\n\", \"\\tF1 score: \", f1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_text = calculate_error_percentage(new_df[\"isImageSarcastic?\"], new_df[\"i_s\"])\n",
    "error_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"image_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
